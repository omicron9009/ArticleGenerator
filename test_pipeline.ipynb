{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3003b8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import glob\n",
    "import random\n",
    "import json\n",
    "import ffmpeg\n",
    "import openai\n",
    "import elevenlabs\n",
    "from dotenv import load_dotenv\n",
    "from mutagen.mp3 import MP3\n",
    "from elevenlabs.client import ElevenLabs\n",
    "\n",
    "# ========================\n",
    "# 1. SETUP & CONFIGURATION\n",
    "# ========================\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "ELEVENLABS_API_KEY = os.getenv(\"ELEVENLABS_API_KEY\")\n",
    "\n",
    "# Check if API keys are set\n",
    "if not OPENAI_API_KEY or not ELEVENLABS_API_KEY:\n",
    "    raise ValueError(\"‚ùå API keys for OpenAI and ElevenLabs must be set in the .env file.\")\n",
    "\n",
    "# Initialize API clients\n",
    "openai_client = openai.OpenAI(api_key=OPENAI_API_KEY)\n",
    "elevenlabs.api_key = ELEVENLABS_API_KEY\n",
    "# Initialize ElevenLabs client\n",
    "elevenlabs = ElevenLabs(\n",
    "    api_key=os.getenv(\"ELEVENLABS_API_KEY\")  # Or replace with your API key directly\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e24461d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_story_with_prompts(user_prompt):\n",
    "    \"\"\"\n",
    "    Generates a content with scenes and image prompts using OpenAI's GPT model.\n",
    "    Each scene text is limited (~60 characters ‚âà 10 sec audio).\n",
    "    \"\"\"\n",
    "    print(\"‚úçÔ∏è  Generating conent and image prompts...\")\n",
    "    system_prompt = \"\"\"\n",
    "    You are a general content generator. Based on the user's prompt, generate texts.\n",
    "    \n",
    "    Output must be a valid JSON with:\n",
    "    - \"title\": A short story title (max 6 words).\n",
    "    - \"scenes\": Exactly 5 items, each with:\n",
    "        1. \"text\": A short story snippet, about 15-20 words ( suitable for ~10 sec TTS audio).\n",
    "        2. \"image_prompt\": A descriptive, visually rich prompt for image generation (1‚Äì2 sentences).\n",
    "    \n",
    "    Strict output format:\n",
    "    {\n",
    "      \"title\": \"The Last Stargazer\",\n",
    "      \"scenes\": [\n",
    "        {\n",
    "          \"text\": \"In a twilight city, Elias adjusted his grandfather's brass telescope, hoping to glimpse the last star before night vanished forever.\",\n",
    "          \"image_prompt\": \"A solitary figure on a futuristic rooftop at dusk, peering through a brass telescope toward a fading star.\"\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        response = openai_client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_prompt}\n",
    "            ],\n",
    "            response_format={\"type\": \"json_object\"}\n",
    "        )\n",
    "        story_data = json.loads(response.choices[0].message.content)\n",
    "        print(\"‚úÖ Story generated successfully.\")\n",
    "        print(story_data)\n",
    "        return story_data\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error generating story: {e}\")\n",
    "        raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb7839ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úçÔ∏è  Generating story and image prompts...\n",
      "‚úÖ Story generated successfully.\n",
      "{'title': 'Whispers of Ancient Maharashtra', 'scenes': [{'text': \"Ancient echoes lingered as the vibrant hues of Maharashtra's terrain unfolded from lush plains to formidable forts.\", 'image_prompt': \"A panoramic view of Maharashtra's diverse landscape, featuring verdant fields and grand, ancient forts under a clear, blue sky.\"}, {'text': 'Time-worn temples whispered tales of devotion, their intricate carvings testament to centuries-old artistry and craftsmanship.', 'image_prompt': 'A close-up of a historic temple in Maharashtra, showcasing its detailed stone carvings and weathered, yet majestic structure.'}, {'text': \"The bustling markets once heard the clamor of traders, each stall a microcosm of Maharashtra's rich, cultural tapestry.\", 'image_prompt': 'A vibrant market scene with colorful stalls, diverse goods on display, and people engaged in lively barter conversations.'}]}\n"
     ]
    }
   ],
   "source": [
    "# --- Get User Input ---\n",
    "user_prompt = input(\"üëâ Enter a prompt for your requirement: \")\n",
    "\n",
    "# --- Generate Content ---\n",
    "story_data = generate_story_with_prompts(user_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8569e019",
   "metadata": {},
   "outputs": [],
   "source": [
    "story_data={'title': 'Whispers of Ancient Maharashtra', 'scenes': [{'text': \"Ancient echoes lingered as the vibrant hues of Maharashtra's terrain unfolded from lush plains to formidable forts.\", 'image_prompt': \"A panoramic view of Maharashtra's diverse landscape, featuring verdant fields and grand, ancient forts under a clear, blue sky.\"}, {'text': 'Time-worn temples whispered tales of devotion, their intricate carvings testament to centuries-old artistry and craftsmanship.', 'image_prompt': 'A close-up of a historic temple in Maharashtra, showcasing its detailed stone carvings and weathered, yet majestic structure.'}, {'text': \"The bustling markets once heard the clamor of traders, each stall a microcosm of Maharashtra's rich, cultural tapestry.\", 'image_prompt': 'A vibrant market scene with colorful stalls, diverse goods on display, and people engaged in lively barter conversations.'}]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5102eec3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(story_data['scenes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3ec5b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define directories\n",
    "IMAGE_DIR = \"output_images\"\n",
    "VIDEO_DIR = \"output_videos\"\n",
    "MUSIC_DIR = \"music\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "27a29557",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_story(story_text):\n",
    "    # Stub: implement your cleaning logic here if needed\n",
    "    return story_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "737f11be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_narration(story_text, filename, voice_id=\"G17SuINrv2H9FC6nvetn\"):\n",
    "    story_text=clean_story(story_text)\n",
    "    # voice_id=\"yFJbqk0f3hzpxkA3vSqT\"\n",
    "    try:\n",
    "        # Stream audio\n",
    "        audio_stream = elevenlabs.text_to_speech.stream(\n",
    "            text=story_text,\n",
    "            voice_id=voice_id,\n",
    "            model_id=\"eleven_multilingual_v2\"\n",
    "        )\n",
    "\n",
    "        # Collect chunks\n",
    "        audio_bytes = b\"\"\n",
    "        for chunk in audio_stream:\n",
    "            if isinstance(chunk, bytes):\n",
    "                audio_bytes += chunk\n",
    "\n",
    "        # Save to file\n",
    "        os.makedirs(\"output_videos\", exist_ok=True)\n",
    "        audio_path = os.path.join(\"output_videos\", filename)\n",
    "        with open(audio_path, \"wb\") as f:\n",
    "            f.write(audio_bytes)\n",
    "\n",
    "        print(\"üéß Narration saved:\", audio_path)\n",
    "        return audio_path\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"‚ùå ElevenLabs TTS Error:\", str(e))\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787f0550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéß Narration saved: output_videos\\ca_narration.mp3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'output_videos\\\\ca_narration.mp3'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_narration_text = story_data.get('title', '') + \". \" + \" \".join([scene['text'] for scene in story_data['scenes']])\n",
    "narration_path=generate_narration(full_narration_text, \"ca_narration.mp3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "707e26a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'Whispers of Ancient Maharashtra',\n",
       " 'scenes': [{'text': \"Ancient echoes lingered as the vibrant hues of Maharashtra's terrain unfolded from lush plains to formidable forts.\",\n",
       "   'image_prompt': \"A panoramic view of Maharashtra's diverse landscape, featuring verdant fields and grand, ancient forts under a clear, blue sky.\"},\n",
       "  {'text': 'Time-worn temples whispered tales of devotion, their intricate carvings testament to centuries-old artistry and craftsmanship.',\n",
       "   'image_prompt': 'A close-up of a historic temple in Maharashtra, showcasing its detailed stone carvings and weathered, yet majestic structure.'},\n",
       "  {'text': \"The bustling markets once heard the clamor of traders, each stall a microcosm of Maharashtra's rich, cultural tapestry.\",\n",
       "   'image_prompt': 'A vibrant market scene with colorful stalls, diverse goods on display, and people engaged in lively barter conversations.'}]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "story_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1706d314",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0657a0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "from google.genai import types\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import os\n",
    "\n",
    "# Gemini client\n",
    "gemini_client = genai.Client()\n",
    "\n",
    "def generate_image(prompt, index):\n",
    "    \"\"\"\n",
    "    Generates an image using Gemini and saves it.\n",
    "    \"\"\"\n",
    "    print(f\"üé® Generating image for scene {index+1}...\")\n",
    "    try:\n",
    "        # Generate content (image + optional text)\n",
    "        response = gemini_client.models.generate_content(\n",
    "            model=\"gemini-2.0-flash-preview-image-generation\",\n",
    "            contents=prompt,\n",
    "            config=types.GenerateContentConfig(\n",
    "                response_modalities=['TEXT', 'IMAGE']\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # Make sure output directory exists\n",
    "        os.makedirs(IMAGE_DIR, exist_ok=True)\n",
    "        image_path = os.path.join(IMAGE_DIR, f\"ca_scene_{index+1}.png\")\n",
    "\n",
    "        # Loop through candidates and save images\n",
    "        for part in response.candidates[0].content.parts:\n",
    "            if part.inline_data is not None:\n",
    "                image = Image.open(BytesIO(part.inline_data.data))\n",
    "                image.save(image_path)\n",
    "                print(f\"‚úÖ Image saved at: {image_path}\")\n",
    "                return image_path\n",
    "        \n",
    "        print(f\"‚ö†Ô∏è No image data returned for scene {index+1}\")\n",
    "        return None\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error generating image for scene {index+1}: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "221142b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üé® Generating image for scene 1...\n",
      "‚úÖ Image saved at: output_images\\scene_1.png\n",
      "üé® Generating image for scene 2...\n",
      "‚úÖ Image saved at: output_images\\scene_2.png\n",
      "üé® Generating image for scene 3...\n",
      "‚úÖ Image saved at: output_images\\scene_3.png\n"
     ]
    }
   ],
   "source": [
    "image_paths=[]\n",
    "for i, scene in enumerate(story_data['scenes']):\n",
    "    img_path = generate_image(scene['image_prompt'], i)\n",
    "    if img_path:\n",
    "        image_paths.append(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb201f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def images_to_video_ffmpeg(image_dir, narration_audio_path, output_dir):\n",
    "    \"\"\"\n",
    "    Stitches images and audio into a video using FFmpeg.\n",
    "    \"\"\"\n",
    "    print(\"üé¨ Starting video creation process...\")\n",
    "    try:\n",
    "        # Get image paths and calculate duration per image\n",
    "        image_paths = sorted(glob.glob(os.path.join(image_dir, \"*.png\")))\n",
    "        if not image_paths:\n",
    "            raise ValueError(\"‚ùå No images found in the provided directory.\")\n",
    "\n",
    "        narration_audio = MP3(narration_audio_path)\n",
    "        total_duration = narration_audio.info.length\n",
    "        duration_per_image = total_duration / len(image_paths)\n",
    "\n",
    "        # Select random background music\n",
    "        music_files = glob.glob(os.path.join(MUSIC_DIR, \"*.mp3\"))\n",
    "        if not music_files:\n",
    "            raise ValueError(\"‚ùå No background music found in music/ directory.\")\n",
    "        bg_music_path = random.choice(music_files)\n",
    "\n",
    "        # Define file paths\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        list_file = \"image_list.txt\"\n",
    "        slideshow_path = os.path.join(output_dir, \"temp_video.mp4\")\n",
    "        mixed_audio_path = os.path.join(output_dir, \"mixed_audio.aac\")\n",
    "        final_output_path = os.path.join(output_dir, \"final_video.mp4\")\n",
    "        \n",
    "        # --- Step 1: Create image list file for FFmpeg ---\n",
    "        with open(list_file, 'w') as f:\n",
    "            for path in image_paths:\n",
    "                f.write(f\"file '{os.path.abspath(path)}'\\n\")\n",
    "                f.write(f\"duration {duration_per_image:.2f}\\n\")\n",
    "            f.write(f\"file '{os.path.abspath(image_paths[-1])}'\\n\") # Ensure last image holds till end\n",
    "\n",
    "        # --- Step 2: Create silent slideshow video ---\n",
    "        (\n",
    "            ffmpeg\n",
    "            .input(list_file, format='concat', safe=0)\n",
    "            .output(slideshow_path, vcodec='libx264', pix_fmt='yuv420p', r=24, vsync='vfr')\n",
    "            .run(overwrite_output=True, quiet=True)\n",
    "        )\n",
    "        print(\"‚úÖ Slideshow created.\")\n",
    "\n",
    "        # --- Step 3: Mix narration and background music ---\n",
    "        main_audio = ffmpeg.input(narration_audio_path)\n",
    "        background_audio = ffmpeg.input(bg_music_path).filter('volume', 0.15)\n",
    "\n",
    "        (\n",
    "            ffmpeg\n",
    "            .filter([main_audio, background_audio], 'amix', inputs=2, duration='first', dropout_transition=0)\n",
    "            .output(mixed_audio_path, acodec='aac')\n",
    "            .run(overwrite_output=True, quiet=True)\n",
    "        )\n",
    "        print(\"‚úÖ Audio mixed.\")\n",
    "\n",
    "        # --- Step 4: Combine slideshow with mixed audio ---\n",
    "        video_input = ffmpeg.input(slideshow_path)\n",
    "        audio_input = ffmpeg.input(mixed_audio_path)\n",
    "        \n",
    "        (\n",
    "            ffmpeg\n",
    "            .output(video_input, audio_input, final_output_path, vcodec='copy', acodec='copy', shortest=None)\n",
    "            .run(overwrite_output=True, quiet=True)\n",
    "        )\n",
    "        \n",
    "        # --- Step 5: Cleanup temporary files ---\n",
    "        os.remove(list_file)\n",
    "        os.remove(slideshow_path)\n",
    "        os.remove(mixed_audio_path)\n",
    "\n",
    "        print(f\"üéâ Final video saved at: {final_output_path}\")\n",
    "        return final_output_path\n",
    "\n",
    "    except ffmpeg.Error as e:\n",
    "        print(\"‚ùå FFmpeg error occurred:\")\n",
    "        print(\"STDOUT:\", e.stdout.decode() if e.stdout else \"N/A\")\n",
    "        print(\"STDERR:\", e.stderr.decode() if e.stderr else \"N/A\")\n",
    "        raise\n",
    "    except Exception as ex:\n",
    "        print(f\"‚ùå An error occurred during video creation: {ex}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a9eec999",
   "metadata": {},
   "outputs": [],
   "source": [
    "narration_path='output_videos\\\\ca_narration.mp3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b2b1917",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üé¨ Starting video creation process...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'ffmpeg' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 8\u001b[39m, in \u001b[36mimages_to_video_ffmpeg\u001b[39m\u001b[34m(image_dir, narration_audio_path, output_dir)\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m      7\u001b[39m     \u001b[38;5;66;03m# Get image paths and calculate duration per image\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m     image_paths = \u001b[38;5;28msorted\u001b[39m(\u001b[43mglob\u001b[49m.glob(os.path.join(image_dir, \u001b[33m\"\u001b[39m\u001b[33m*.png\u001b[39m\u001b[33m\"\u001b[39m)))\n\u001b[32m      9\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m image_paths:\n",
      "\u001b[31mNameError\u001b[39m: name 'glob' is not defined",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mimages_to_video_ffmpeg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mIMAGE_DIR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnarration_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mVIDEO_DIR\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 75\u001b[39m, in \u001b[36mimages_to_video_ffmpeg\u001b[39m\u001b[34m(image_dir, narration_audio_path, output_dir)\u001b[39m\n\u001b[32m     72\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33müéâ Final video saved at: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfinal_output_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     73\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m final_output_path\n\u001b[32m---> \u001b[39m\u001b[32m75\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[43mffmpeg\u001b[49m.Error \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     76\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m‚ùå FFmpeg error occurred:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     77\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mSTDOUT:\u001b[39m\u001b[33m\"\u001b[39m, e.stdout.decode() \u001b[38;5;28;01mif\u001b[39;00m e.stdout \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mN/A\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'ffmpeg' is not defined"
     ]
    }
   ],
   "source": [
    "images_to_video_ffmpeg(IMAGE_DIR, narration_path, VIDEO_DIR)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
